# Grafana Dashboards

This directory contains Grafana dashboard definitions for monitoring the microservices.

## Dashboards

### API Processing Service Dashboard
**File:** `api-processing-dashboard.json`

Monitors the API Processing service with the following metrics:
- Request rate (requests per second)
- Request duration (p50, p95 percentiles)
- HTTP status code distribution
- Average request size

### API Status Service Dashboard
**File:** `api-status-dashboard.json`

Monitors the API Status service with the following metrics:
- Request rate (requests per second)
- Request duration (p50, p95 percentiles)
- HTTP status code distribution
- Cosmos DB query performance

### Worker Service Dashboard
**File:** `worker-dashboard.json`

Monitors the AI Worker service with the following metrics:
- Messages processed rate
- Message processing duration (p50, p95 percentiles)
- OpenAI API request rate and success/error breakdown
- OpenAI API request duration (p50, p95 percentiles)
- Current number of messages being processed

## Importing Dashboards

After deploying the infrastructure with Terraform, you can import these dashboards into Azure Managed Grafana:

1. Navigate to your Azure Managed Grafana instance
2. Go to Dashboards â†’ Import
3. Upload the JSON files from this directory
4. Configure the Prometheus data source to point to your Azure Monitor Workspace

## Metrics Exposed

### FastAPI Services (api-processing, api-status)
The FastAPI services use `prometheus-fastapi-instrumentator` which automatically exposes:
- `http_requests_total` - Total HTTP requests
- `http_request_duration_seconds` - HTTP request duration histogram
- `http_request_size_bytes` - HTTP request size
- `http_response_size_bytes` - HTTP response size

Metrics endpoint: `/metrics`

### Worker Service
The worker service exposes custom metrics using `prometheus-client`:
- `worker_messages_processed_total` - Total messages processed (labeled by status: success/error)
- `worker_messages_processing_duration_seconds` - Time spent processing messages
- `worker_openai_requests_total` - Total OpenAI API requests (labeled by status: success/error)
- `worker_openai_request_duration_seconds` - Time spent on OpenAI API requests
- `worker_messages_in_queue` - Current number of messages being processed

Metrics endpoint: `:8000/metrics`

## Data Collection

Prometheus metrics are scraped by Azure Monitor Workspace using the Data Collection Rule configured in `terraform/prometheus_grafana.tf`.
